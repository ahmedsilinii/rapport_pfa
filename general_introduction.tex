\addcontentsline{toc}{section}{General Introduction}

The rapid evolution of artificial intelligence (AI) and mobile technologies has brought transformative changes across multiple domains, including healthcare. These advancements are now enabling the design of intelligent systems that support early disease detection, remote monitoring, and accessible diagnostics. One area of growing relevance is respiratory health, particularly in light of the increased attention to respiratory diseases following the COVID-19 pandemic and the continued burden of chronic conditions such as asthma, chronic obstructive pulmonary disease (COPD), and sleep apnea.

Despite the prevalence of such conditions, access to timely and affordable respiratory screening remains limited in many parts of the world. Specialized medical equipment and trained professionals are often required to conduct auscultation and interpret respiratory anomalies. This reality poses a significant barrier to early detection and long-term monitoring—two factors that are critical to improving patient outcomes. The proliferation of smartphones, however, opens new opportunities for building accessible, AI-powered health tools that can reach broader populations.

This end-of-year project seeks to address this challenge by designing and implementing a mobile application capable of analyzing breathing sounds and providing AI-assisted respiratory diagnostics. The system enables users to record audio samples using a smartphone microphone, which are then processed using machine learning models trained to classify respiratory anomalies such as wheezing, crackles, and rhonchi. Based on the classification results, the system offers a preliminary diagnostic suggestion. To enhance usability and trust, a conversational AI assistant is also integrated—allowing users to ask questions, receive explanations, and obtain medically grounded feedback.

The core objective of the project is to provide a portable and intelligent solution for respiratory disease detection, one that combines ease of use, technical robustness, and medical relevance. Achieving this goal involves contributions across multiple areas of computer science, including mobile development, signal processing, deep learning, backend architecture, and natural language processing.

The mobile application is built using a cross-platform framework, ensuring compatibility with both Android and iOS devices. It includes modules for secure user authentication, audio recording, and diagnosis history tracking. The backend infrastructure, powered by a backend-as-a-service platform, supports encrypted data storage, API integration, and serverless functions for model inference. On the AI side, two main components are developed: (1) a contrastive learning model (CLAP) for respiratory sound classification, and (2) a lightweight retrieval-augmented generation (RAG) chatbot based on a quantized language model. These components are trained on publicly available datasets and fine-tuned to deliver fast, accurate, and explainable results to end users.

Beyond implementation, this report provides a structured exploration of the project lifecycle, from the initial definition of objectives to system evaluation. Chapter 1 introduces the general context, the underlying problem, and the proposed solution. Chapter 2 outlines the foundational concepts that support the system, including respiratory anomalies, deep learning principles, and mobile development strategies. Chapter 3 presents a review of related work in respiratory diagnostics and medical chatbots. Chapters 4 and 5 detail the application of the CRISP-DM methodology to both the classification model and the AI assistant. Chapter 6 focuses on implementation, highlighting system architecture, mobile development, backend integration, and the tools used.

Through this interdisciplinary work, we aim not only to demonstrate the feasibility of smartphone-based respiratory diagnostics, but also to contribute to the broader field of AI for public health. By combining modern machine learning techniques with accessible mobile interfaces, the project aspires to bring preliminary respiratory screening closer to users—anytime, anywhere.
